{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Articles_RecSys_Izhevskaya_A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d78e587a84424d0587092fb72d1d2bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25a5c867f2a5495cb29fe8f8488815f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e903d17d97b042919116fb088e996b0b",
              "IPY_MODEL_28884bec60a448ddb1e1959d02ec5d69"
            ]
          }
        },
        "25a5c867f2a5495cb29fe8f8488815f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e903d17d97b042919116fb088e996b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2095abaf77b0471d9b48d6bd203ab33b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_342cff79a02944c19131fe1e9467f226"
          }
        },
        "28884bec60a448ddb1e1959d02ec5d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cace54fba65542909c23ded1bbae7664",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "328050it [00:14, 22917.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8064ba8f4bf14fafb67ff57c75f6d98a"
          }
        },
        "2095abaf77b0471d9b48d6bd203ab33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "342cff79a02944c19131fe1e9467f226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cace54fba65542909c23ded1bbae7664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8064ba8f4bf14fafb67ff57c75f6d98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kie8w17nEfPK",
        "colab_type": "text"
      },
      "source": [
        "# Articles RecSys\n",
        "\n",
        "---\n",
        "\n",
        "В данном ноутбуке содержится мое решение для соревнования по ИАД Articles RecSys. После рассмотрения всех возможных вариантов (после долгого, очень долгого пути проб и ошибок...)  я решила использовать Гибридный подход в данной задаче и применить факторизационную машину (библиотека Lightfm), которая эффективно использует данные о взаимодействиях пользователей с айтемами, а также учитывает метаинформацию о пользователях/айтемах (в нашем случае об айтемах). Таким образом, удается эффективнее справляться с проблемой холодного старта."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpbf1wiiMEFG",
        "colab_type": "code",
        "outputId": "d8f7a7b4-eb28-499e-807a-2bebef1fbdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "! pip3 install lightfm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.6/dist-packages (1.15)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaDc1X-Tlc3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# импортируем необходимые библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "\n",
        "#import tqdm\n",
        "from scipy.sparse import csr_matrix,  coo_matrix, vstack, hstack\n",
        "from scipy.sparse import eye as eye\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tfdf\n",
        "from lightfm import LightFM\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import string\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjF4_GqdlyH8",
        "colab_type": "code",
        "outputId": "584e7e8a-2747-49f6-8780-7749e3fe1359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# код для загрузки датасета с помощью kaggle api (нужен файл kaggle.json)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "import kaggle\n",
        "!kaggle competitions download -c recsys-iad-challenge\n",
        "\n",
        "! unzip \"/content/items.json.zip\"\n",
        "! unzip \"/content/train.json.zip\"\n",
        "! unzip \"/content/random_benchmark.csv.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading random_benchmark.csv.zip to /content\n",
            "  0% 0.00/10.9M [00:00<?, ?B/s]\n",
            "100% 10.9M/10.9M [00:00<00:00, 100MB/s]\n",
            "Downloading train.json.zip to /content\n",
            " 98% 230M/235M [00:02<00:00, 111MB/s] \n",
            "100% 235M/235M [00:02<00:00, 106MB/s]\n",
            "Downloading items.json.zip to /content\n",
            " 96% 353M/368M [00:06<00:00, 28.3MB/s]\n",
            "100% 368M/368M [00:06<00:00, 56.1MB/s]\n",
            "Archive:  /content/items.json.zip\n",
            "  inflating: items.json              \n",
            "Archive:  /content/train.json.zip\n",
            "  inflating: train.json              \n",
            "Archive:  /content/random_benchmark.csv.zip\n",
            "  inflating: random_benchmark.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KemnB-sx32wm",
        "colab_type": "code",
        "outputId": "820fd5e2-2bc4-48ce-cb59-1f2f0b72dc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "d78e587a84424d0587092fb72d1d2bcd",
            "25a5c867f2a5495cb29fe8f8488815f8",
            "e903d17d97b042919116fb088e996b0b",
            "28884bec60a448ddb1e1959d02ec5d69",
            "2095abaf77b0471d9b48d6bd203ab33b",
            "342cff79a02944c19131fe1e9467f226",
            "cace54fba65542909c23ded1bbae7664",
            "8064ba8f4bf14fafb67ff57c75f6d98a"
          ]
        }
      },
      "source": [
        "# данный код для загрузки описания айтемов был любезно предоставлен нашим преподавателем\n",
        "\n",
        "%%time\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "items_list=[]\n",
        "with tqdm(open('./items.json')) as inf:\n",
        "  for line in inf:\n",
        "    item=json.loads(line)\n",
        "    items_list.append(item)\n",
        "\n",
        "items_df=pd.DataFrame(items_list).set_index('itemId')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d78e587a84424d0587092fb72d1d2bcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 13.6 s, sys: 1.66 s, total: 15.3 s\n",
            "Wall time: 14.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4oQC00FJwUX",
        "colab_type": "text"
      },
      "source": [
        "## Пару слов о фичах\n",
        "\n",
        "---\n",
        "\n",
        "Я решила использовать  tf-idf как самый доступный и при этом достаточно эффективный метод для получения векторных представлений. Были использованы  title и content, предварительно обработанные с целью удаления знаков препинания. Полученные матрицы, несущие в себе информацию о контенте статьи, были сконкатенированы и скормлены фактаризационной машине в качестве item_features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65R9UH0lyYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция для простенькой предобработки текста\n",
        "def delete_punctuation(x):\n",
        "\n",
        "\n",
        "    punctuation = list(string.punctuation)\n",
        "    return ''.join([a if a not in punctuation + ['«»\\n--'] else ' ' for a in x])\n",
        "\n",
        "\n",
        "items_df.title = items_df.title.apply(delete_punctuation)\n",
        "items_df.content = items_df.content.apply(delete_punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-TmEnVXNILR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создание фичей\n",
        "vectorizer_t = tfdf(lowercase=False, min_df=90, max_df=0.01)\n",
        "tf_idf_titles = vectorizer_t.fit_transform(items_df.title.values)\n",
        "vectorizer_c = tfdf(lowercase=False, min_df=90, max_df=0.01)\n",
        "tf_idf_content = vectorizer_c.fit_transform(items_df.content.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l18UHek1Ore0",
        "colab_type": "code",
        "outputId": "f00d584d-7582-4441-f620-c68ed2ec33a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# identity матрица \n",
        "num_items= len(items_df)\n",
        "a = eye(num_items)\n",
        "# полученные фичи, которые мы подадим в факторизационную машину\n",
        "items_features =hstack([a, tf_idf_titles, tf_idf_content], format=\"csr\")\n",
        "items_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<328050x387044 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 23797064 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B0M5m6RSZEQ",
        "colab_type": "code",
        "outputId": "5101f019-e729-41a5-bea4-35e4a9b4c3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# код для загрузки основного датасета и создания из него спарс матрицы \n",
        "users = []\n",
        "items = []\n",
        "data = []\n",
        "\n",
        "with open(\"/content/train.json\", 'r') as f:\n",
        "  for line in f:\n",
        "    user = json.loads(line)\n",
        "    for item, rating in user['trainRatings'].items():\n",
        "      users.append(user['userId'])\n",
        "      items.append(item)\n",
        "      if rating == 0:\n",
        "        data.append(-1)\n",
        "      else:\n",
        "        data.append(rating)\n",
        "  \n",
        "# основные данные в формате coo_matrix: клики обозначены 1 (позитивное взаимодействие)\n",
        "# и отсутствие кликов -1 (негативное взаимодействие)\n",
        "interaction_matrix = coo_matrix((data, (users, list(map(int, items)))))\n",
        "interaction_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<42977x328050 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 67780168 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpfvjA5gMULM",
        "colab_type": "text"
      },
      "source": [
        "# Обучение модели\n",
        "\n",
        "---\n",
        "\n",
        "Итак, в итоге лучший результат был получен с помощью модели с векторами размерностью 150 (были попробованы и другие: но меньше - ухудшается качество, больше - слишком долгое время обучения). В качестве оптимизируемой функции был выбран logloss, так как присутствуют как позитивные, так и негативные взаимодействия. Модель обучалась  5 эпох."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWluszfnenP9",
        "colab_type": "code",
        "outputId": "08f24c7c-a6ba-4d8a-d671-9d8d67dafc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "n_Components = 150\n",
        "n_Epochs = 5\n",
        "seed= 10\n",
        "\n",
        "model= LightFM(loss=\"logistic\", no_components=n_Components, random_state=seed)\n",
        "                          \n",
        "model.fit_partial(interaction_matrix, item_features=items_features, epochs=n_Epochs, num_threads=cpu_count(), verbose=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fb9a41fd8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rih1_tGFOKIJ",
        "colab_type": "text"
      },
      "source": [
        "## Создание итогового сабмита для кэггл\n",
        "\n",
        "---\n",
        "\n",
        "В этой части все просто - с помощью полученной модели и фичей создаем предсказание для пользователей из файла random_benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWanIo8HOec3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = pd.read_csv('/content/random_benchmark.csv')\n",
        "prediction['preds'] = model.predict(prediction.userId.values,\n",
        "                                    prediction.itemId.values,\n",
        "                                    item_features = items_features,\n",
        "                                    num_threads=cpu_count())\n",
        "\n",
        "\n",
        "prediction.sort_values(['userId', 'preds'], ascending=[True, False], inplace=True)\n",
        "prediction.drop('preds', axis=1, inplace=True)\n",
        "\n",
        "prediction.to_csv('with_identity1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}